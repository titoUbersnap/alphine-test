// Generated by dts-bundle-generator v5.9.0

//   <reference types="node" />
//  <reference types="offscreencanvas" />

declare global {
    interface MediaTrackConstraints {
        resizeMode?: ConstrainDOMString;
    }
}
/** Web address or data url */
export declare type Url = string;
/** Video playback customization options */
export declare type VideoOptions = Partial<Pick<HTMLVideoElement, 'loop'>>;
export type ImageSource =
    | HTMLImageElement
    | HTMLVideoElement
    | HTMLCanvasElement
    | ImageData;
export type ImageDataLike = Pick<ImageData, 'width' | 'height' | 'data'> & {
    format: 'RGB' | 'RGBA';
};
export interface RenderingContext {
    width: number;
    height: number;
    /**
     * Draws a source into the context.
     * The source pixels are consumed from the top left-corner to the right-bottom corner.
     * The drawing starts at [dx, dy] and goes to [dx+dw, dy+dh].
     * @example
     * ```ts
     * // will draw the source into 20x10 rectangle
     * ctx.drawImage(source, 0, 0, 20, 10)
     * ```
     * @example
     * ```ts
     * // will draw the source into 20x10 rectangle flipped horizontally
     * ctx.drawImage(source, 20, 0, -20, 10)
     * ```
     */
    drawImage(
        source: ImageSource,
        dx: number,
        dy: number,
        dw: number,
        dh: number
    ): Promise<void>;
    getImageData(
        sx: number,
        sy: number,
        sw: number,
        sh: number
    ): Promise<ImageDataLike>;
    dispose(): void;
}
export declare type FramingOptions = {
    /**
     * Mirrors the source frames by X axis
     * @example
     * ```ts
     * player.use(
     *  new MediaStream(
     *    await navigator.mediaDevices.getUserMedia({ video: true }),
     *  ),
     *  {
     *    horizontalFlip: true,
     *  },
     * )
     * ```
     */
    horizontalFlip: boolean;
    /**
     * Resizes the source frames
     * @example
     * ```ts
     * player.use(
     *  new Webcam(),
     *  {
     *    // renders frames of half of the original resolution
     *    resize: (width, height) => [width / 2, height / 2],
     *  },
     * )
     * ```
     */
    resize: (
        frameWidth: number,
        frameHeight: number
    ) => [renderWidth: number, renderHeight: number];
    /**
     * Crops the source frame (after resize if any)
     * @example
     * ```ts
     * player.use(
     *  new Webcam(),
     *  {
     *    // renders square frames
     *    resize: (width, height) => [(width - height) / 2, 0, height, height],
     *  },
     * )
     */
    crop: (
        renderWidth: number,
        renderHeight: number
    ) => [cropX: number, cropY: number, cropWidth: number, cropHeight: number];
};
/**
 * {@link Player} input from image
 *
 * Supports the same mime-types as [img.src](https://developer.mozilla.org/en-US/docs/Web/HTML/Element/img#attr-src)
 * @category Input
 */
export declare class Image implements Input {
    private readonly _src;
    /**
     * Creates Image input from the given {@link Url}
     * @example
     * ```ts
     * const photo = new Image("https://placekitten.com/200/300")
     * ```
     */
    constructor(source: Url);
    /**
     * Creates Image input from the given {@link https://developer.mozilla.org/en-US/docs/Web/API/Blob | Blob}
     * @example
     * ```ts
     * const file = $("#file-input").files[0] // File is subclass of Blob
     * const photo = new Image(file)
     * ```
     */
    constructor(source: Blob);
    /** Yields image as a sequence of {@link https://developer.mozilla.org/en-US/docs/Web/API/ImageData | ImageData} frames */
    [Symbol.asyncIterator](
        options?: InputOptions
    ): ReturnType<Input[typeof Symbol.asyncIterator]>;
}
/**
 * {@link Player} input from {@link https://developer.mozilla.org/en-US/docs/Web/API/MediaStream/MediaStream | MediaStream}
 * @category Input
 */
export declare class MediaStream implements Input {
    private static readonly cache;
    private _video;
    private _stream;
    /**
     * Creates MediaStream input from {@link https://developer.mozilla.org/en-US/docs/Web/API/MediaStream/MediaStream | MediaStream}
     * @example
     * ```ts
     * const stream = new MediaStream(
     *  await navigator.mediaDevices.getUserMedia({ video: true })
     * )
     * ```
     */
    constructor(stream: globalThis.MediaStream);
    /** Yields media stream as a sequence of {@link https://developer.mozilla.org/en-US/docs/Web/API/ImageData | ImageData} frames */
    [Symbol.asyncIterator](
        options?: InputOptions
    ): ReturnType<Input[typeof Symbol.asyncIterator]>;
    /** Stops underlying media stream */
    stop(): void;
}
/** @category Input */
export declare const defaultVideoOptions: VideoOptions;
/**
 * {@link Player} input from video
 *
 * Supports the same mime-types as [video.src](https://developer.mozilla.org/en-US/docs/Web/HTML/Element/video#attr-src)
 * @category Input
 */
export declare class Video implements Input {
    private _video;
    private _ctx;
    private readonly _src;
    private readonly _options;
    /**
     * Creates Video input from the given {@link Url}
     * @example
     * ```ts
     * const video = new Video("https://www.youtube.com/watch?v=sv4EWcMs3xE")
     * ```
     */
    constructor(source: Url, options?: VideoOptions);
    /**
     * Creates Video input from the given {@link https://developer.mozilla.org/en-US/docs/Web/API/Blob | Blob}
     * @example
     * ```ts
     * const file = $("#file-input").files[0] // File is subclass of Blob
     * const video = new Image(file, { loop: true })
     * ```
     */
    constructor(source: Blob, options?: VideoOptions);
    /** @internal */
    constructor(source: MediaStream, options?: VideoOptions);
    /** Yields video as a sequence of {@link https://developer.mozilla.org/en-US/docs/Web/API/ImageData | ImageData} frames */
    [Symbol.asyncIterator](
        options?: InputOptions
    ): ReturnType<Input[typeof Symbol.asyncIterator]>;
    /** Stops underlying video */
    stop(): void;
}
/**
 * Default webcam {@link https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamConstraints/video | video constraints} to apply
 * @category Input
 */
export declare const defaultVideoConstraints: MediaTrackConstraints;
/**
 * {@link Player} input from webcam video
 * @category Input
 */
export declare class Webcam implements Input {
    private _stream;
    private readonly _constraints;
    /**
     * @param videoConstraints - constraints to be merged with {@link defaultVideoConstraints}
     * and to be passed to {@link https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia | navigator.mediaDevices.getUserMedia()}
     */
    constructor(videoConstraints?: MediaTrackConstraints);
    /**
     * Manually starts webcam
     *
     * > Ordinary webcam is lazily started during async iteration over it.
     *
     * > But sometimes you may want to manually pre-start webcam e.g during parallel creation of a {@link Player} instance:
     * > ```ts
     * > const [webcam, player] = await Promise.all([
     * >  new Webcam().start(),
     * >  Player.create({ clientToken: "xxx-xxx-xxx" }),
     * > ])
     * >
     * > player.use(webcam)
     * > ```
     */
    start(): Promise<this>;
    /** Yields webcam video as sequence of {@link https://developer.mozilla.org/en-US/docs/Web/API/ImageData | ImageData} frames */
    [Symbol.asyncIterator]({
        horizontalFlip,
        ...options
    }?: InputOptions): ReturnType<Input[typeof Symbol.asyncIterator]>;
    /** Turns off webcam */
    stop(): void;
}
/**
 * Customizes production of {@link Input} frames
 * @category Input
 */
export declare type InputOptions = Partial<FramingOptions>;
/**
 * Interface for {@link Player} input
 * @category Input
 */
export interface Input {
    /** Yields sequence of {@link https://developer.mozilla.org/en-US/docs/Web/API/ImageData | ImageData} frames  */
    [Symbol.asyncIterator](
        options?: InputOptions
    ): AsyncGenerator<ImageDataLike>;
}
/**
 * Not designed for public use, use on your own risk
 * @hidden
 */
export declare const utils: {
    createRenderingContext: (
        canvas?: HTMLCanvasElement | OffscreenCanvas | undefined,
        settings?:
            | CanvasRenderingContext2DSettings
            | WebGLContextAttributes
            | undefined
    ) => RenderingContext;
    createVideoElement: (
        source: string | Blob | MediaStream,
        options?: Partial<Pick<HTMLVideoElement, 'loop'>>
    ) => Promise<HTMLVideoElement>;
};
/** Other WebAssembly declarations, for compatibility with older versions of Typescript */
export declare namespace WebAssembly {
    interface Module {}
}
export declare namespace Emscripten {
    interface FileSystemType {}
    type EnvironmentType = 'WEB' | 'NODE' | 'SHELL' | 'WORKER';
    type JSType = 'number' | 'string' | 'array' | 'boolean';
    type TypeCompatibleWithC = number | string | any[] | boolean;
    type CIntType = 'i8' | 'i16' | 'i32' | 'i64';
    type CFloatType = 'float' | 'double';
    type CPointerType =
        | 'i8*'
        | 'i16*'
        | 'i32*'
        | 'i64*'
        | 'float*'
        | 'double*'
        | '*';
    type CType = CIntType | CFloatType | CPointerType;
    type WebAssemblyImports = Array<{
        name: string;
        kind: string;
    }>;
    type WebAssemblyExports = Array<{
        module: string;
        name: string;
        kind: string;
    }>;
    interface CCallOpts {
        async?: boolean | undefined;
    }
}
export interface EmscriptenModule {
    print(str: string): void;
    printErr(str: string): void;
    arguments: string[];
    environment: Emscripten.EnvironmentType;
    preInit: Array<{
        (): void;
    }>;
    preRun: Array<{
        (): void;
    }>;
    postRun: Array<{
        (): void;
    }>;
    onAbort: {
        (what: any): void;
    };
    onRuntimeInitialized: {
        (): void;
    };
    preinitializedWebGLContext: WebGLRenderingContext;
    noInitialRun: boolean;
    noExitRuntime: boolean;
    logReadFiles: boolean;
    filePackagePrefixURL: string;
    wasmBinary: ArrayBuffer;
    destroy(object: object): void;
    getPreloadedPackage(
        remotePackageName: string,
        remotePackageSize: number
    ): ArrayBuffer;
    instantiateWasm(
        imports: Emscripten.WebAssemblyImports,
        successCallback: (module: WebAssembly.Module) => void
    ): Emscripten.WebAssemblyExports;
    locateFile(url: string, scriptDirectory: string): string;
    onCustomMessage(event: MessageEvent): void;
    // USE_TYPED_ARRAYS == 1
    HEAP: Int32Array;
    IHEAP: Int32Array;
    FHEAP: Float64Array;
    // USE_TYPED_ARRAYS == 2
    HEAP8: Int8Array;
    HEAP16: Int16Array;
    HEAP32: Int32Array;
    HEAPU8: Uint8Array;
    HEAPU16: Uint16Array;
    HEAPU32: Uint32Array;
    HEAPF32: Float32Array;
    HEAPF64: Float64Array;
    TOTAL_STACK: number;
    TOTAL_MEMORY: number;
    FAST_MEMORY: number;
    addOnPreRun(cb: () => any): void;
    addOnInit(cb: () => any): void;
    addOnPreMain(cb: () => any): void;
    addOnExit(cb: () => any): void;
    addOnPostRun(cb: () => any): void;
    preloadedImages: any;
    preloadedAudios: any;
    _malloc(size: number): number;
    _free(ptr: number): void;
}
export declare namespace FS {
    interface Lookup {
        path: string;
        node: FSNode;
    }
    interface FSStream {}
    interface FSNode {}
    interface ErrnoError {}
    let ignorePermissions: boolean;
    let trackingDelegate: any;
    let tracking: any;
    let genericErrors: any;
    //
    // paths
    //
    function lookupPath(path: string, opts: any): Lookup;
    function getPath(node: FSNode): string;
    //
    // nodes
    //
    function isFile(mode: number): boolean;
    function isDir(mode: number): boolean;
    function isLink(mode: number): boolean;
    function isChrdev(mode: number): boolean;
    function isBlkdev(mode: number): boolean;
    function isFIFO(mode: number): boolean;
    function isSocket(mode: number): boolean;
    //
    // devices
    //
    function major(dev: number): number;
    function minor(dev: number): number;
    function makedev(ma: number, mi: number): number;
    function registerDevice(dev: number, ops: any): void;
    //
    // core
    //
    function syncfs(populate: boolean, callback: (e: any) => any): void;
    function syncfs(callback: (e: any) => any, populate?: boolean): void;
    function mount(
        type: Emscripten.FileSystemType,
        opts: any,
        mountpoint: string
    ): any;
    function unmount(mountpoint: string): void;
    function mkdir(path: string, mode?: number): any;
    function mkdev(path: string, mode?: number, dev?: number): any;
    function symlink(oldpath: string, newpath: string): any;
    function rename(old_path: string, new_path: string): void;
    function rmdir(path: string): void;
    function readdir(path: string): any;
    function unlink(path: string): void;
    function readlink(path: string): string;
    function stat(path: string, dontFollow?: boolean): any;
    function lstat(path: string): any;
    function chmod(path: string, mode: number, dontFollow?: boolean): void;
    function lchmod(path: string, mode: number): void;
    function fchmod(fd: number, mode: number): void;
    function chown(
        path: string,
        uid: number,
        gid: number,
        dontFollow?: boolean
    ): void;
    function lchown(path: string, uid: number, gid: number): void;
    function fchown(fd: number, uid: number, gid: number): void;
    function truncate(path: string, len: number): void;
    function ftruncate(fd: number, len: number): void;
    function utime(path: string, atime: number, mtime: number): void;
    function open(
        path: string,
        flags: string,
        mode?: number,
        fd_start?: number,
        fd_end?: number
    ): FSStream;
    function close(stream: FSStream): void;
    function llseek(stream: FSStream, offset: number, whence: number): any;
    function read(
        stream: FSStream,
        buffer: ArrayBufferView,
        offset: number,
        length: number,
        position?: number
    ): number;
    function write(
        stream: FSStream,
        buffer: ArrayBufferView,
        offset: number,
        length: number,
        position?: number,
        canOwn?: boolean
    ): number;
    function allocate(stream: FSStream, offset: number, length: number): void;
    function mmap(
        stream: FSStream,
        buffer: ArrayBufferView,
        offset: number,
        length: number,
        position: number,
        prot: number,
        flags: number
    ): any;
    function ioctl(stream: FSStream, cmd: any, arg: any): any;
    function readFile(
        path: string,
        opts: {
            encoding: 'binary';
            flags?: string | undefined;
        }
    ): Uint8Array;
    function readFile(
        path: string,
        opts: {
            encoding: 'utf8';
            flags?: string | undefined;
        }
    ): string;
    function readFile(
        path: string,
        opts?: {
            flags?: string | undefined;
        }
    ): Uint8Array;
    function writeFile(
        path: string,
        data: string | ArrayBufferView,
        opts?: {
            flags?: string | undefined;
        }
    ): void;
    //
    // module-level FS code
    //
    function cwd(): string;
    function chdir(path: string): void;
    function init(
        input: null | (() => number | null),
        output: null | ((c: number) => any),
        error: null | ((c: number) => any)
    ): void;
    function createLazyFile(
        parent: string | FSNode,
        name: string,
        url: string,
        canRead: boolean,
        canWrite: boolean
    ): FSNode;
    function createPreloadedFile(
        parent: string | FSNode,
        name: string,
        url: string,
        canRead: boolean,
        canWrite: boolean,
        onload?: () => void,
        onerror?: () => void,
        dontCreateFile?: boolean,
        canOwn?: boolean
    ): void;
    function createDataFile(
        parent: string | FSNode,
        name: string,
        data: ArrayBufferView,
        canRead: boolean,
        canWrite: boolean,
        canOwn: boolean
    ): FSNode;
}
export declare namespace Emscripten {
    // https://github.com/emscripten-core/emscripten/blob/752f66a7434386b4a8ed6e0e6babdafc23d78047/system/include/emscripten/bind.h#L1762-L1769
    export abstract class Vector<T> {
        push_back(value: T): void;
        size(): number;
        get(index: number): T | undefined;
        set(index: number, value: T): boolean;
    }
}
export declare interface EmscriptenModule {
    FS: typeof FS;
    PThread?: any;
    canvas: HTMLCanvasElement;
    createContext: (
        canvas: HTMLCanvasElement,
        useWebGL?: boolean,
        setInModule?: boolean,
        webGLContextAttributes?: WebGLContextAttributes
    ) => void;
    setCanvasSize: (width: number, height: number, noUpdates?: boolean) => void;
}
export declare type EmscriptenModuleOptions = {
    canvas?: EmscriptenModule['canvas'] | undefined;
    locateFile?: EmscriptenModule['locateFile'] | undefined;
    mainScriptUrlOrBlob?: string | undefined;
};
declare abstract class EmscriptenObject {
    // https://github.com/emscripten-core/emscripten/blob/9b2514760dbcbec049ad6c332a038e5c735be7fa/src/embind/embind.js#L1748-L1752
    isAliasOf(): boolean;
    clone(): this;
    delete(): void;
    isDeleted(): boolean;
    deleteLater(): void;
}
export declare interface EmscriptenModule {
    getExceptionMessage: (exceptionPtr: number) => string;
}
export declare namespace BanubaSDK {
    export class VectorFloat extends EmscriptenObject {}
    export class VectorUint8 extends EmscriptenObject {}
    export class VectorInt32 extends EmscriptenObject {}
    export class VectorString extends EmscriptenObject {}
    export enum SeverityLevel {
        INFO,
        DEBUG,
        WARNING,
        ERROR,
    }
}
export declare namespace BanubaSDK {
    export enum FaceSearchMode {
        FAST,
        GOOD,
        GOOD_FOR_FIRST_FACE,
    }
    export class UtilityManager extends EmscriptenObject {
        static initialize(paths: VectorString, clientToken: string): void;
        static setLogLevel(level: SeverityLevel): void;
    }
}
export declare namespace BanubaSDK {
    export class Vec3 {
        x: number;
        y: number;
        z: number;
    }
    export class Vec4 {
        x: number;
        y: number;
        z: number;
        w: number;
    }
    export class Mat4x4 {
        m11: number;
        m12: number;
        m13: number;
        m14: number;
        m21: number;
        m22: number;
        m23: number;
        m24: number;
        m31: number;
        m32: number;
        m33: number;
        m34: number;
        m41: number;
        m42: number;
        m43: number;
        m44: number;
    }
    export class Mat3x4 {
        m11: number;
        m12: number;
        m13: number;
        m14: number;
        m21: number;
        m22: number;
        m23: number;
        m24: number;
        m31: number;
        m32: number;
        m33: number;
        m34: number;
    }
    export class Mat2x4 {
        m11: number;
        m12: number;
        m13: number;
        m14: number;
        m21: number;
        m22: number;
        m23: number;
        m24: number;
    }
    /**  Class, represents RenderTarget (render pass) class */
    export class RenderTarget {
        /** @return render target name (string) */
        getName(): string;
        /** @param samples (int) msaa samples counts */
        setSamplesCount(samples: number): void;
        /** @return msaa samples counts */
        getSamplesCount(): number;
        /** set render target surface extent
         * @param width (int): surface width
         * @param height (int): surface height */
        setExtent(width: number, height: number): void;
        /** @return render target width (int) */
        getWidth(): number;
        /** @return render target height (int) */
        getHeight(): number;
        /** set render target surface extent scale
         * @param width (int): surface width scale
         * @param height (int): surface height scale */
        setScale(scale: number): void;
        /** @return render target width scale (int) */
        getScale(): number;
        /** add color or depth Attachment to render target
         * @param Attachment (Image): surface Attachment */
        addAttachment(Attachment: Image): void;
        /** removes color or depth Attachment from render target, if it was aded early
	. * @param attachment (Image): surface Attachment */
        removeAttachment(Attachment: Image): void;
        /** @returns list of added Attachments (Emscripten.Vector<Image>). */
        getAttachments(): Emscripten.Vector<Image>;
    }
    export enum ImageType {
        ATTACHMENT,
        CUBEMAP,
        SEGM_MASK,
        TEXTURE,
        VIDEO,
        LUT,
        CAMERA_TEXTURE,
    }
    export enum CameraTextureFormat {
        Y,
        UV,
        RGBA,
    }
    export enum AttachmentType {
        COLOR,
        DEPTH,
    }
    export enum TextureFilteringMode {
        POINT,
        LINEAR,
        TRILINEAR,
    }
    export enum RenderBackendType {
        WGPU,
        OPENGL,
        WEBGL1,
    }
    /** Class, represents render target Attachment. Subclass of Image */
    export class Attachment extends Image {
        /** @return Attachment type (AttachmentType). Can be color, or depth */
        getAttachmentType(): AttachmentType;
        /** @param color (Vec3). Also implisity set Attachment load behaviour to clear. */
        setClearColor(color: Vec3): void;
        /** @return Attachment clear color (Vec3) */
        getClearColor(): Vec3;
        /** set Attachment width
	. * @param width (int) */
        setWidth(value: number): void;
        /** set Attachment height
	. * @param height (int) */
        setHeight(value: number): void;
        /** @return Attachment width (int) */
        getWidth(): number;
        /** @return Attachment height (int) */
        getHeight(): number;
        /** set Attachment Texture filtering mode
	. * param mode (TextureFilteringMode) */
        setFilteringMode(value: TextureFilteringMode): void;
        /** @return filtering mode (TextureFilteringMode) */
        getFilteringMode(): TextureFilteringMode;
    }
    /** Class, which repesent Cubemap Texture class. Subclass of Image */
    export class Cubemap extends Image {
        /** Load Cubemap Texture data from specified file name. For now only supported .ktx (cuemap) Images.
	. * @param fileName (string): absolute path for Image file. */
        load(filename: string): void;
    }
    export enum SegmentationMaskType {
        BACKGROUND,
        HAIR,
        SKIN,
        LIPS,
        L_EYE,
        R_EYE,
        LIPS_SHINING,
        OCCLUSION,
        BODY,
        HAIR_STRAND,
    }
    /** Class, which repesent neural networks segmentation mask Texture class. Subclass of Image */
    export class SegmentationMask extends Image {
        /** @return segmentation mask type. Can be background, hair, skin, lips, lEye, rEye. */
        getMaskType(): SegmentationMaskType;
        /** set segmentation mask activity flag
	. * @param active (boolean): segmentation mask activity flag */
        setActive(active: boolean): void;
        /** @return segmentation mask activity flag (boolean). */
        isActive(): boolean;
    }
    /** Class, which repesent 2D Texture class. Subclass of Image */
    export class Texture extends Image {
        /** Load Texture data from specified file name. For now only supported .png, .jpeg, .jpg, .ktx (2d) Images.
	. * @param fileName (string): absolute path for Image file */
        load(fileName: string): void;
        /** @return width (int) of loaded Image */
        getWidth(): number;
        /** @return height (int) of loaded Image */
        getHeight(): number;
        /** @return channels count of loaded Image (R, RG, RGBA, i.e. 1, 2, or 4). */
        getLayers(): number;
        /** set mimpap generation flag. (affect only on ogl backend).
	. * @param enable (boolean): mipmap generation enable flag. */
        setMips(enable: boolean): void;
        /** @return flag (boolean) : mimpap generation flag  */
        hasMips(): boolean;
        /** enable/disable Texture tiling
	. * @param enable (boolean): tiled wrapping flag */
        setTiling(enable: boolean): void;
        /** @return tiled Texture wrapping flag (boolean). */
        getTiling(): boolean;
        /** set Texture filtering mode
	. * param mode (TextureFilteringMode) */
        setFiltering(type: TextureFilteringMode): void;
        /** @return filtering mode (TextureFilteringMode) */
        getFilteringMode(): TextureFilteringMode;
    }
    /** Special class, which represent web or phone camera Image Textures. Because of different platfroms can provide YUV,
	  or RGBA camera Texture representations camera Texture can be represented in Y, UV, RGBA formats, depends on
	  platfrom. Subclass of Image */
    export class CameraTexture extends Image {
        /** @return camera Texture format (CameraTextureFormat). Can be Y, UV, or RGBA. */
        getFormat(): CameraTextureFormat;
        /** set camera Texture format for current Texture.
	. * @param format (CameraTextureFormat). Can be Y, UV, or RGBA. */
        setFormat(format: CameraTextureFormat): void;
    }
    export class WeightedLut {
        setWeight(value: number): void;
        getWeight(): number;
        load(fileName: string): void;
    }
    export class TextTexture {
        getWidth(): number;
        getHeight(): number;
        setWidth(value: number): void;
        setHeight(value: number): void;
        setText(text: string): void;
        getText(): string;
        setFont(path: string): void;
        getFont(): string;
    }
    /** Base class, which represented basic Image class */
    export class Image {
        /** @return Image name (string) */
        getName(): string;
        /** @return Image type. type of Image subclass (enum, can be Attachment, Cubemap, SegmentationMask, Texture, CameraTexture, Video, WeightedLut) */
        getType(): ImageType;
        /** cast to Attachment subclass. May throw. */
        asAttachment(): Attachment;
        /** cast to Cubemap subclass. May throw. */
        asCubemap(): Cubemap;
        /** cast to SegmentationMask subclass. May throw. */
        asSegmentationMask(): SegmentationMask;
        /** cast to Texture subclass. May throw. */
        asTexture(): Texture;
        /** cast to CameraTexture subclass. May throw. */
        asCameraTexture(): CameraTexture;
        /** cast to Video subclass. May throw. */
        asVideo(): Video;
        /** cast to WeightedLut subclass. May throw. */
        asWeightedLut(): WeightedLut;
        /** cast to TextTexture subclass. May throw. */
        asTextTexture(): TextTexture;
    }
    /** Base class, represents Media files handling. */
    export class Media {
        /** set playback start position.
	. * @param position (float): playback start position (seconds) */
        setStartPosition(position: number): void;
        /** set playback end position.
	. * @param position (float): playback end position (seconds) */
        setEndPosition(position: number): void;
        /** set playback looping.
	. * @param looped (boolean): loop playback flag */
        setLooped(looped: boolean): void;
        /** @return loop playback flag (boolean) */
        isLooped(): boolean;
        /** @return playback start position (float) */
        getStartPosition(): number;
        /** @return playback end position (float) */
        getEndPosition(): number;
        /** @return playback active flag. */
        isPlaying(): boolean;
        /** starts Video playback */
        play(): void;
        /** pause Video playback */
        pause(): void;
        /** stop Video playback */
        stop(): void;
        /** resume paused Video playback */
        resume(): void;
    }
    /** Class, represents Video Texture class. Subclass of Image, also subclass of Media. */
    export class Video extends Media {
        /** @return current loaded Video file (string). */
        getCurrentVideo(): string;
        /** @return current loaded Video pixels width (int). */
        getWidth(): number;
        /** @return current loaded Video pixels height (int). */
        getHeight(): number;
        /** Load Video file for decoding.
	. * @param fileName (string): absolute path for Video file. */
        load(VideoPath: string): void;
        /** cast Video to Media parent class (Media). */
        asMedia(): Media;
    }
    /** Class represents audio track class. Subclass of Media */
    export class AudioTrack extends Media {
        /** set current audio track playback volume.
	. * @param volume (float): new audio volume. must be in range [0, 1] */
        setVolume(volume: number): void;
        /** @return current audio track playback volume (float) */
        getVolume(): number;
        /** Load audio track file. For now only supports .m4a, .ogg, .mp3 files.
	. * @param file (string): absolute path for audio track file. */
        load(file: string): void;
        /** @return current loaded audio track (string). */
        getCurrentTrack(): string;
        /** cast AudioTrack to Media parent class (Media). */
        asMedia(): Media;
    }
    /** Class, represent shader Parameter. */
    export class Parameter {
        /** Fabric method for Parameter creating.
	. * @param name (string): Parameter name.
	. * @return created Parameter (Parameter) */
        static create(name: string): Parameter;
        /** @return Parameter name (string) */
        getName(): string;
        /** set Parameter integer value.
	. * @param value (int) */
        setInteger(value: number): void;
        /** return Parameter int value. Throw is type is not equal type, which was added earlier. */
        getInteger(): number;
        /** set Parameter real value.
	. * @param value (float) */
        setReal(value: number): void;
        /** return Parameter number value. Throw is type is not equal type, which was added earlier. */
        getReal(): number;
        /** set Parameter string value.
	. * @param value (string) */
        setString(value: string): void;
        /** return Parameter string value. Throw is type is not equal type, which was added earlier. */
        getString(): string;
        /** set Parameter Vec3 value.
	. * @param value (Vec3) */
        setVector3(value: Vec3): void;
        /** return Parameter Vec3 value. Throw is type is not equal type, which was added earlier. */
        getVector3(): Vec3;
        /** set Parameter Vec4 value.
	. * @param value (Vec4) */
        setVector4(value: [x: number, y: number, z: number, w: number]): void;
        /** return Parameter Vec4 value. Throw is type is not equal type, which was added earlier. */
        getVector4(): Vec4;
        /** set Parameter Mat2x4 value.
	. * @param value (Mat2x4) */
        setMat2x4(value: Mat2x4): void;
        /** return Parameter Mat2x4 value. Throw is type is not equal type, which was added earlier. */
        getMat2x4(): Mat2x4;
        /** set Parameter Mat3x4 value.
	. * @param value (Mat3x4) */
        setMat3x4(value: Mat3x4): void;
        /** return Parameter Mat3x4 value. Throw is type is not equal type, which was added earlier. */
        getMat3x4(): Mat3x4;
        /** set Parameter Mat4x4 value.
	. * @param value (Mat4x4) */
        setMat4x4(value: Mat4x4): void;
        /** return Parameter Mat4x4 value. Throw is type is not equal type, which was added earlier. */
        getMat4x4(): Mat4x4;
    }
    export enum BlendingMode {
        OFF,
        ALPHA,
        PREMUL_ALPHA,
        SCREEN,
        ADD,
        MULTIPLY,
        MIN,
        MAX,
    }
    export class State {
        blending: BlendingMode;
        zWrite: boolean;
        zTest: boolean;
        colorWrite: boolean;
        backFaces: boolean;
    }
    export enum GeometryTopology {
        TRIANGLESLIST,
        LINESLIST,
        POINTSLIST,
    }
    /** Class, represents material class */
    export class Material {
        /** @return material name (string) */
        getName(): string;
        /** adds shader Parameter to Parameters list, after what you'll can get access to this Parameter in shader by it's name.
	. * Type of Parameter in shader will match with type of Parameter, except int, float, vector2, vector3,
	. * this types will be replaces on Vec4, which x component will have needed value, other components will be filled by garbage.
	. * @param Parameter (Parameter): Parameter to add */
        addParameter(Parameter: Parameter): void;
        /** @return list of shader Parameters (Emscripten.Vector<Parameter>) */
        getParameters(): Emscripten.Vector<Parameter>;
        /** removes Parameter from list. */
        /** @param Parameter (Parameter): Parameter to remove */
        removeParameter(Parameter: Parameter): void;
        /** find Parameter by name
	. * @param name (string)
	. * @return Parameter (Parameter) or null */
        findParameter(name: string): Parameter;
        /** set material geometry topology.
	. * @param topology (geometryTopology): geometry topology type. Can be trianglesList, linesList, pointsList. Default: trianglesList */
        setTopology(topology: GeometryTopology): void;
        /** @return current geometry topology (geometryTopology) */
        getCurrentTopology(): GeometryTopology;
        /** sets render state (i.e blending mode, color/depth writing, depth testing, etc.)
	. * @param state (state) render state */
        setState(state: State): void;
        /** @return render state (state) */
        getState(): State;
        /** add Image sampler, after what you'll can get acess to Image and sampler in shader by formula: ImageIndex = i * 2. samplerIndex = i * 2 + 1.
	. * Where i is Image index in Images list (which you can get by getImages call).
	. * Note that you need to export Images samplers in shader manually and sampler name in name must match with sampler name in material.
	. * @param sampler (string): sampler name
	. * @param Image (Image): sampler Image */
        addImage(sampler: string, Image: Image): void;
        /** @return list of samplers Images (Emscripten.Vector<Parameter>) */
        getImages(): Emscripten.Vector<Image>;
        /** removes Image from list (if exist). Will be ignored if effect was activated. */
        /** @param sampler (string): sampler name */
        removeImage(sampler: string): void;
        /** @return list of samplers name (Emscripten.Vector<string>) */
        getSamplers(): Emscripten.Vector<string>;
    }
    /** Class, represents 3D mesh class */
    export class Mesh {
        /** @return mesh name (string) */
        getName(): string;
        /** @return sub geometries names list (Emscripten.Vector<string>) */
        getSubGeometries(): Emscripten.Vector<string>;
        /** @return animations names list (Emscripten.Vector<string>) */
        getAnimations(): Emscripten.Vector<string>;
    }
    /** Class, represents face resources */
    export class Face {
        /** @return face name (string) */
        getName(): string;
        /** @return face index (int) */
        getIndex(): number;
        /** sets face index for face. Face mesh and Textures will be updated according their faces index.
	. * If index will be greater than max faces can be found face resources update will be ignored.
	. * @param index (int): face index */
        setIndex(index: number): void;
        /** sets face mesh. Must be only \"$builtin$meshes/face.stream\" mesh.
	. * @param mesh (mesh): face mesh */
        setFaceMesh(mesh: Mesh): void;
        /** @return face mesh (mesh) */
        getFaceMesh(): Mesh;
    }
    export enum MorphingType {
        BEAUTY,
        MESH,
    }
    /** Class, represents morphing resources */
    export class Morphing {
        /** set morphing type. Can be beauty or mesh.
	. * @param type (morphingType): morphing type */
        setType(type: MorphingType): void;
        /** @return morphing type (morphingType) */
        getType(): MorphingType;
        /** @return morphing name (string) */
        getName(): string;
        /** sets morphing warp mesh. If morhping type is beauty must be only \"$builtin$meshes/beauty\" mesh.
	. * @param mesh (mesh): morphing warp mesh */
        setWarpMesh(mesh: Mesh): void;
        /** @return warp (mesh) */
        getWarpMesh(): Mesh;
    }
    /** Factory for assets creating and their data uploading. */
    export class AssetManager {
        /** create Image of given type
	. * @param name (string): Image name
	. * @param type (ImageType): Image type
	. * @return created Image (Image). */
        createImage(name: string, type: ImageType): Image;
        createSegmentationMask(name: string, type: SegmentationMaskType): Image;
        /** creates render target
	. * @param name (string): render target name
	. * @return created render target (RenderTarget). */
        createRenderTarget(name: string): RenderTarget;
        /** creates AudioTrack
	. * @param name (string): audio track name
	. * @return created audio track (AudioTrack). */
        createAudioTrack(name: string): AudioTrack;
        /** creates face
	. * @param name (string): face name
	. * @return created face (face). */
        createFace(name: string): Face;
        /** creates morphing
	. * @param name (string): morphing name
	. * @return created morphing (morphing). */
        createMorph(name: string): Morphing;
        /** creates mesh
	. * @param name (string): mesh name
	. * @return created mesh (mesh). */
        createMesh(name: string): Mesh;
        /** upload mesh file
	. * @param mesh (mesh): mesh
	. * @param fileName (string): file to upload */
        uploadMeshData(mesh: Mesh, fileName: string): void;
        /** creates material
	. * @param name (string): material name
	. * @return created material (material). */
        createMaterial(name: string): Material;
        /** upload material shaders
	. * @param material (material): material
	. * @param fileName (string): shaders to upload */
        uploadMaterialData(material: Material, fileName: string): void;
        /** Find Image by specified name. Returns null if Image not found.
	. * @param name (string) Image name. */
        findImage(name: string): Image;
        /** Find render target by specified name. Returns null if render target not found.
	. * @param name (string) render target name. */
        findRenderTarget(name: string): RenderTarget;
        /** Find audio track by specified name. Returns null if audio track not found.
	. * @param name (string) audio track name. */
        findAudioTrack(name: string): AudioTrack;
        /** Find face by specified name. Returns null if face not found.
	. * @param name (string) face name. */
        findFace(name: string): Face;
        /** Find morph by specified name. Returns null if morph not found.
	. * @param name (string) morph name. */
        findMorph(name: string): Morphing;
        /** Find mesh by specified name. Returns null if mesh not found.
	. * @param name (string) mesh name. */
        findMesh(name: string): Mesh;
        /** Find material by specified name. Returns null if material not found.
	. * @param name (string) material name. */
        findMaterial(name: string): Material;
    }
    export enum ProjectionType {
        ORTHOGRAPHIC,
        PERSPECTIVE,
    }
    export class CameraParameters {
        projection: ProjectionType;
        zNear: number;
        zFar: number;
        fov: number;
        frameWidth: number;
        frameHeight: number;
    }
    export class Camera {
        setParameters(Parameters: CameraParameters): void;
        getParameters(): CameraParameters;
    }
    export class EyesStatus {
        isLeftOpen: boolean;
        isRightOpen: boolean;
    }
    /** Face tracker component. All transformations components of entity with faceTracker component will update
	 relatively face, which index was specified in face asset. Also updates face asset resources. Subclass of component. */
    export class FaceTracker extends Component {
        /** Fabric method for face tracker creating.
	. * @return face tracker component (faceTracker) */
        static create(): FaceTracker;
        /** Sets face to face tracker.
	. * @param face (face): face asset */
        setFace(face: Face): void;
        /** @return face (face): face asset */
        getFace(): Face;
        /** true if fase with index, specified in face asset was recognized
	. * @return face recognition flag (boolean) */
        hasFace(): boolean;
        /** true if mouth is open
	. * @return flag (boolean) */
        isMouthOpen(): boolean;
        /** true if is smiling
	. * @return flag (boolean) */
        isSmiling(): boolean;
        /** true if eyebrows up
	. * @return flag (boolean) */
        isEyebrowsUp(): boolean;
        /** true if disgust
	. * @return flag (boolean) */
        isDisgust(): boolean;
        /** @return eyes status (eyesStatus) */
        getEyesStatus(): EyesStatus;
    }
    export class Transformation3d extends Component {
        /** Fabric method for transformation creating.
	. * @return transformation component (transformation) */
        static create(): Transformation3d;
        /** Sets transformation translation value.
	. * @param position (Vec3): translation value. */
        setTranslation(position: Vec3): void;
        /** @return translation value (Vec3). */
        getTranslation(): Vec3;
        /** Sets transformation rotations angles. Angles must be in degrees.
	. * @param rotation (Vec3): rotation value. */
        setRotation(anglesDeg: Vec3): void;
        /** @return scale value (Vec3). */
        getRotation(): Vec3;
        /** Sets transformation scale value.
	. * @param scale (Vec3): scale value. */
        setScale(factor: Vec3): void;
        /** @return rotation value (Vec3). */
        getScale(): Vec3;
    }
    export enum AnimationMode {
        OFF,
        LOOP,
        ONCE,
        ONCE_REVERSED,
        FIXED,
    }
    /** class for adjustment physics simulation. */
    export class PhysicsSimulator {
        /** Sets gravitation vector.
	. * @param gravity (Vec3): gravity value */
        setGravity(gravity: Vec3): void;
        /** Sets damping value.
	. * @param damping (float): damping value */
        setDamping(damping: number): void;
        /** Sets inverse bone mass.
	. * @param boneName (string): bone name
	. * @param value (float): inverse bone mass */
        setInvMass(boneName: string, value: number): void;
        /** Add sphere collider.
	. * @param sphereIndex (int): index for sphere
	. * @param center (Vec3): sphere center in world space
	. * @param radius (float): sphere radius */
        setSphereCollider(
            sphereIndex: number,
            center: Vec3,
            radius: number
        ): void;
        /** Add constraint between bone1 and bone2.
	. * @param bone1Name (string): from bone name
	. * @param bone2Name (string): to bone name
	. * @param distance (float): constaint length */
        setConstraint(
            bone1Name: string,
            bone2Name: string,
            distance: number
        ): void;
        /** Reset simulator to default state */
        reset(): void;
    }
    /** class which is the container for meshes and materials and provide class for animation controlling. Subclass of component */
    export class MeshInstance extends Component {
        /** Fabric method for meshInstance creating.
	. * @return meshInstance component (meshInstance) */
        static create(): MeshInstance;
        /** set mesh visibility flag. Will be overridden if entity with meshInstance component is child of entity with faceTracker component.
	. * @param visible(boolean) visibility flag. */
        setVisible(visible: boolean): void;
        /** @return visibility flag (boolean) */
        isVisible(): boolean;
        /** set for mesh sub geometry with specified name specified material if sub geometry with given name exists.
	. * @param subGeometryName (string) sub geometry name.
	. * @param material (material) sub geometry material. */
        setSubGeometryMaterial(
            subGeometryName: string,
            material: Material
        ): void;
        /** returns material from mesh sub geometry with specified name if it exist, null otherwise
	. * @param subGeometryName (string) sub geometry name.
	. * @return sub geometry material (material). */
        getSubGeometryMaterial(subGeometryName: string): Material;
        /** get materials for each sub geometry
	. * @return materials (Emscripten.Vector<material>) */
        getMaterials(): Emscripten.Vector<Material>;
        /** set mesh for given mesh instance. Of some mesh was settled before need to re set all materials. */
        /** @param mesh (mesh) new mesh. */
        setMesh(mesh: Mesh): void;
        /** @return mesh (mesh). */
        getMesh(): Mesh;
        /** Change current animation if animation with specified name exist.
	. * @param name (string) new animation.
	. * @param mode (animationMode). */
        animationChange(animation: string, mode: AnimationMode): void;
        /** Start animation playback. */
        animationPlay(): void;
        /** pause animation playback. */
        animationPause(): void;
        /** Set current animation playback position.
	. * @param positionNs (long): position in ns. */
        animationSeek(positionNs: number): void;
        /** True if animation playback was started.
	. * @return animation playback active flag (boolean). */
        isAnimationPlaying(): boolean;
        /** True if animation playback stop.
	. * @return animation playback active flag (boolean). */
        isAnimationEnded(): boolean;
        /** @return current setted animation name (string). */
        getAnimation(): string;
        /** @return current setted animation mode (animationMode). Can be off loop once onceReversed fixed. */
        getAnimationMode(): AnimationMode;
        /** @return current animation playback position (long). */
        getAnimationPositionNs(): number;
        /** @return current animation playback duration (long). */
        getAnimationDurationNs(): number;
        /** Returns current animation playback time offset from begin(0). Typycally equals animation position mod animation duration.
	. * @return animation playback time offset (long). */
        getAnimationTimeOffset_ns(): number;
        /** Set current animation playback time offset from begin(0). duration.
	. * @param timeNs (long): animation playback time offset. */
        setAnimationTimeOffset_ns(timeNs: number): void;
        /** @return physicsSimulator of current meshInstance  */
        getPhysicsSimulator(): PhysicsSimulator;
    }
    /** class which is controller for beauty morphing update. Subclass of faceMorphing. */
    export class BeautyMorphing extends FaceMorphing {
        /** Sets face morphing weight.
	. * @param value (float) morphing weight. */
        setFaceWeight(value: number): void;
        /** @return morphing weight (float). */
        getFaceWeight(): number;
        /** Sets nose morphing weight.
	. * @param value (float) morphing weight. */
        setNoseWeight(value: number): void;
        /** @return morphing weight (float). */
        getNoseWeight(): number;
        /** Sets nose morphing weight.
	. * @param value (float) morphing weight. */
        setEyesWeight(value: number): void;
        /** @return morphing weight (float). */
        getEyesWeight(): number;
    }
    /** class which is the container for morphind and update it's resources. Subclass of component. */
    export class FaceMorphing extends Component {
        /** Fabric method for faceMorphing creating.
	. * @return created (faceMorphing). */
        static create(type: MorphingType): FaceMorphing;
        /** Sets morphing asset.
	. * @param morph (morphing) morphing instance. */
        setMorphing(morph: Morphing): void;
        /** @return setted morphing (morphing). */
        getMorphing(): Morphing;
        /** Cast to beautyMorphing subclass. */
        asBeautyMorphing(): BeautyMorphing;
        /** @return visible(boolean) visibility flag. */
        isVisible(): boolean;
        /** Set faceMorphing visibility flag.
	. * Will be overridden if entity with meshInstance component is child of entity with faceTracker component. Subclass of component.
	. * @param visible(boolean) visibility flag. */
        setVisible(visible: boolean): void;
        /** set morphing weight. Must be in range [0, 1]
	. * @param weight (float) */
        setWeight(weight: number): void;
        /** @return current morph weight (float) */
        getWeight(): number;
    }
    export enum ComponentType {
        FACE_TRACKER,
        TRANSFORMATION,
        MESH_INSTANCE,
        FACE_MORPHING,
    }
    /** Base component class. */
    export class Component {
        /** @return component type. Can be faceTracker, transformation, meshInstance or faceMorphing. */
        getComponentType(): ComponentType;
        /** cast component to face tracker subclass instance. Will throw if derived class is not instance of faceTracker. */
        asFaceTracker(): FaceTracker;
        /** cast component to meshInstance subclass instance. Will throw if derived class is not instance of meshInstance. */
        asMeshInstance(): MeshInstance;
        /** cast component to faceMorphing subclass instance. Will throw if derived class is not instance of faceMorphing. */
        asFaceMorphing(): FaceMorphing;
        /** cast component to transformation3d subclass instance. Will throw if derived class is not instance of transformation3d. */
        asTransformation(): Transformation3d;
    }
    /** A container for entities, which is needed for explicit grouping entities in order in which they will be sent to render.
	 All morph entities must lay on the same layer. */
    export class Layer {
        /** Fabric method for layer creating.
	. * @return created layer (layer). */
        static create(name: string): Layer;
        /** set layer name
	. * @param layer name (string) */
        setName(name: string): void;
        /** @return layer name (string) */
        getName(): string;
        /** Set enable/disable layer flag. The disabled layer will not be rendered.
	. * @param active (boolean) activity flag. */
        setActive(active: boolean): void;
        /** @return activity flag (boolean) */
        isActive(): boolean;
        /** ability for enable/disable morphing in specified layer
	. * @param enable (boolean) */
        enableMorphing(enable: boolean): void;
        /** @return is morphing enable in the current layer */
        isMorphingEnabled(): boolean;
    }
    /**  A structure element of the scene.
	  
	  To construct a scene, you should form a hierarchy of entities to create its
	  structure, then add different components such as lights, cameras, and
	  geometry to entities to create visible content.
	  
	  Each entity has a name which could be used for finding the entity in a hierarchy.
	  
	  Entities in the scene form a tree hierarchy between parents and children.
	  
	  Each entity could be in an enabled or disabled state. The disabling of the entity
	  is equivalent to removing the entity and all its children from the hierarchy.
	  
	  An entity is a container for components. Each entity could contain several components,
	  but only one component of each component type. The Transform component is mandatory
	  and it implicitly placed in each entity.
	  */
    export class Entity {
        /** Fabric method for entity creating.
	. * @return created entity (entity). */
        static create(name: string): Entity;
        /**  Set a new name to the entity. Name could be empty.
	. * @param name (string): new entity name. */
        setName(name: string): void;
        /** @return entity name (string) */
        getName(): string;
        /** add entiy as child to hierarchy
	. * @param child (entity): child entity. */
        addChild(child: Entity): void;
        /** remove entiy as child to hierarchy
	. * @param child (entity): child entity. */
        removeChild(child: Entity): void;
        /** get all child entites list. */
        getChildren(): Emscripten.Vector<Entity>;
        /** remove all child entites list. */
        clearChildren(): void;
        /**  Perform depth-first traverse of entity tree.
	. *  Return first found child with name `entityName` or NULL if such an entity doesn't exist.
	. * @param entityName (string): name of desired entity
	. * @return found entity (entity) or null */
        findChildByName(entityName: string): Entity;
        /** @return parent entity and null if given entity is root. */
        getParent(): Entity;
        /** Set enable/disable entity flag. The disabling of the entity is equivalent to removing the entity and all its children from the hierarchy.
	. * @param active (boolean) activity flag. */
        setActive(active: boolean): void;
        /** @return activity flag (boolean) */
        isActive(): boolean;
        /** Add entity for given layer if it is wasn't added before.
	. * @param layer (layer): layer to add. */
        addIntoLayer(layer: Layer): void;
        /** Removes entity from given layer if it is was added before.
	. * @params layer (layer): layer from remove. */
        removeFromLayer(layer: Layer): void;
        /** returns list of layers in which entity was added. */
        getLayers(): Emscripten.Vector<Layer>;
        /** add given component to entity if component of given type wasn't added before. */
        /** @param component (component): component to add. */
        addComponent(component: Component): void;
        /** check if component of given type was added.
	. * @param componentType (componentType): component type to check.
	. * @return flag (boolean) */
        hasComponent(type: ComponentType): boolean;
        /** get component of given type.
	. * @param componentType (componentType): component type to get.
	. * @return component of given type (component) */
        getComponent(type: ComponentType): Component;
        /** remove given component to entity if component of given component was added before.
	. * @param component (component): component to remove. */
        removeComponent(component: Component): void;
    }
    /** A list of render task.
	 Every task consist of entites layer to draw, render target in which draw, and optional
	 list of sub geomteries names. Cannot be changed after effect activation. */
    export class RenderList {
        /** Fabric method for renderList creating.
	. * @return created render list (renderList). */
        static create(name: string): RenderList;
        /** Set name of the render list
	. * @param name (string) */
        setName(name: string): void;
        /** @return name (string) of the render list */
        getName(): string;
        /** add render task to layer.
	. * @param layer (layer): entities layer.
	. * @param target (RenderTarget): needed render target. Do not change if previous target was the same. (Target changing will trigger start/finish behavior.)
	. * @param subGeoms (optional<Emscripten.Vector<string>>): if specified: only sub geometries from this list will be rendered. */
        addTask(
            layer: Layer,
            target: RenderTarget,
            subGeoms?: Emscripten.Vector<string>
        ): number;
        /** return render rask layer, by render task index. Throw if index >= tasks size.
	. * @param taskIndex (int): render task index.
	. * @return task layer (layer) */
        getTaskLayer(taskIndex: number): Layer;
        /** return render rask render target, by render task index. Throw if index >= tasks size.
	. * @param taskIndex (int): render task index.
	. * @return task render target (RenderTarget) */
        getTaskTarget(taskIndex: number): RenderTarget;
        /** Remove all render tasks. */
        clear(): void;
    }
    /**  A class representing a displayable scene. Aggregates in one place the
	  hierarchy of Entities with their Components,  AssetManager and Renderlist
	  and makes it work all together. */
    export class Scene {
        /**  Set a new name for a scene. The name could be empty. */
        setName(name: string): void;
        /**  Get a scene name. */
        getName(): string;
        /**  Get the root of entities hierarchy. It always exists and has a name \"Root\". */
        getRoot(): Entity;
        /**  Get the AssetManager of a current scene. It always exists. */
        getAssetManager(): AssetManager;
        addLayer(layer: Layer): void;
        getLayers(): Emscripten.Vector<Layer>;
        /**  Get all components present in this scene of specified type */
        getComponents(type: ComponentType): Emscripten.Vector<Component>;
        /**  Return first found layer with name `layerName` or NULL if such layer doesn't exist. */
        getLayer(layerName: string): Layer;
        removeLayer(layer: Layer): void;
        getRenderList(): RenderList;
        setRenderList(renderList: RenderList): void;
        clearRenderList(): void;
        getCamera(): Camera;
    }
    /**  Information getters */
    export class RenderInfo {
        /**  Recognition engine version */
        static getFrxVersion(): number;
        /**  Platfrom name: ios, android */
        static getPlatform(): string;
    }
}
export declare namespace BanubaSDK {
    export enum PixelFormat {
        RGB,
        RGBA,
    }
    export class FeatureParameter {
        readonly x: number;
        readonly y: number;
        readonly z: number;
        readonly w: number;
        constructor(x: number, y: number, z: number, w: number);
    }
    export class VectorFeatureParameter extends Emscripten.Vector<FeatureParameter> {}
}
export declare namespace BanubaSDK {
    export enum CameraOrientation {
        DEG_0,
        DEG_90,
        DEG_180,
        DEG_270,
    }
    export enum ConsistencyMode {
        SYNCHRONOUS,
        SYNCHRONOUS_WHEN_EFFECT_LOADED,
        ASYNCHRONOUS_INCONSISTENT,
        ASYNCHRONOUS_CONSISTENT,
    }
    export class Effect extends EmscriptenObject {
        scene(): Scene;
        dumpFs(outDir: string): void;
        /** Dumps the effect in-place */
        dump(): void;
        dumpJson(): string;
        url(): string;
        callJsMethod(methodName: string, methodJSONParams: string): string;
        evalJs(code: string, resultCallback: (result: string) => void): void;
    }
    export class EffectManager extends EmscriptenObject {
        addEffectActivatedListener(activated: (url: string) => any): void;
        load(url: string): Effect;
        loadAsync(url: string): Effect;
        current(): Effect;
        setEffectVolume(level: number): void;
        setEffectSize(width: number, height: number): void;
    }
    export class EffectPlayerConfiguration extends EmscriptenObject {
        constructor(
            width: number,
            height: number,
            nnEnable: boolean,
            faceSearchMode: FaceSearchMode,
            jsDebuggerEnable: boolean,
            manualAudio: boolean
        );
    }
    export type FrameDurationListener = (
        instantDuration: number,
        averagedDuration: number
    ) => any;
    export class FrameData extends EmscriptenObject {
        static makeFromBpc8(
            dataPtr: number,
            width: number,
            height: number,
            orientation: CameraOrientation,
            format: PixelFormat,
            requireMirroring: boolean,
            faceOrientation: 0
        ): FrameData;
        getRuler(): number;
        addFeatureParameters(parameters: VectorFeatureParameter): void;
    }
    export class EffectPlayer extends EmscriptenObject {
        static create(configuration: EffectPlayerConfiguration): EffectPlayer;
        addFrameDurationListener(
            recognizer: FrameDurationListener,
            camera: FrameDurationListener,
            render: FrameDurationListener
        ): void;
        addFrameDataListener(frameData: (frameData: FrameData) => any): void;
        surfaceCreated(width: number, height: number): void;
        surfaceChanged(width: number, height: number): void;
        surfaceDestroyed(): void;
        recognizerProcessFromBuffer(): void;
        draw(): number;
        pushFrameData(frameData: FrameData): void;
        pushFrameDataWithNumber(
            frameData: FrameData,
            frameNumber: number
        ): void;
        effectManager(): EffectManager;
        setMaxFaces(maxFaces: number): void;
        setRenderConsistencyMode(mode: ConsistencyMode): void;
    }
}
declare function instantiate<T extends EmscriptenModuleOptions>(
    options: T
): Promise<T & EmscriptenModule & typeof BanubaSDK>;
export interface Logger {
    debug?(...data: any[]): void;
    info?(...data: any[]): void;
    warn?(...data: any[]): void;
    error?(...data: any[]): void;
}
export declare type BanubaSDKBinary =
    | 'BanubaSDK.data'
    | 'BanubaSDK.wasm'
    | 'BanubaSDK.simd.wasm';
export declare type BanubaSDKBinaryFileLocator =
    | string
    | ((fileName: BanubaSDKBinary) => string)
    | Record<BanubaSDKBinary, string>
    | Record<Exclude<BanubaSDKBinary, 'BanubaSDK.simd.wasm'>, string>;
/**
 * Keeps a Emscripten Object generated inside a {@link tidy} from being disposed automatically.
 *
 * Inspired by {@link https://js.tensorflow.org/api/latest/#keep | tf.keep}
 * @internal
 */
export declare const keep: <T extends EmscriptenObject>(obj: T) => T;
/**
 * Executes the provided function `fn` and after it is executed,
 * cleans up all intermediate Emscripten Objects allocated by `fn` except those returned by `fn`.
 * The `fn` must not return a Promise (async functions not allowed).
 *
 * Using this method helps avoid memory leaks.
 * In general, wrap calls to operations in `tidy()` for automatic memory cleanup.
 *
 * Inspired by {@link https://js.tensorflow.org/api/latest/#tidy | tf.tidy}
 * @internal
 */
export declare const tidy: <TRet extends unknown>(fn: () => TRet) => TRet;
export declare type SDK = Awaited<ReturnType<typeof instantiate>>;
export declare type SDKOptions = {
    /** Banuba Client token */
    clientToken: string;
    /**
     * Ordinary you won't use the option
     *
     * Overrides internal `canvas` element used for WebGL rendering
     * @default HTMLCanvasElement
     */
    canvas?: HTMLCanvasElement;
    /**
     * Where to find `.wasm` and `.data` files relative to the page running the script
     * @example
     * ```ts
     * const player = await Player.create({
     *    clientToken: "xxx-xxx-xxx",
     *    locateFile: "static/webar/",
     * })
     * ```
     * @example
     * ```ts
     * const player = await Player.create({
     *    clientToken: "xxx-xxx-xxx",
     *    locateFile: (fileName) => "static/webar/" + fileName,
     * })
     * ```
     * @example
     * ```ts
     * const player = await Player.create({
     *    clientToken: "xxx-xxx-xxx",
     *    locateFile: {
     *      "BanubaSDK.data": "static/webar/BanubaSDK.data",
     *      "BanubaSDK.wasm": "static/webar/BanubaSDK.wasm",
     *      "BanubaSDK.simd.wasm": "static/webar/BanubaSDK.simd.wasm", // .simd.wasm is optional
     *   },
     * })
     * ```
     */
    locateFile?: BanubaSDKBinaryFileLocator;
    /**
     * A custom logger instance, pass `{}` to suppress all outputs
     * @default { warn: console.warn, error: console.error }
     */
    logger?: Logger;
};
/** @internal */
export declare function createSDK({
    clientToken,
    locateFile: fileLocator,
    canvas,
    logger,
    ...rest
}: SDKOptions): Promise<
    EmscriptenModuleOptions & EmscriptenModule & typeof BanubaSDK
>;
declare class EventEmitter implements EventTarget {
    private _emitter;
    constructor();
    addEventListener(
        ...args: Parameters<EventTarget['addEventListener']>
    ): void;
    removeEventListener(
        ...args: Parameters<EventTarget['removeEventListener']>
    ): void;
    dispatchEvent(...args: Parameters<EventTarget['dispatchEvent']>): boolean;
    removeAllEventListeners(): void;
}
/** @category Core */
export declare type PlayerOptions = {
    /**
     * Ordinary you won't use the option
     *
     * Overrides `devicePixelRatio` used for proper rendering on hiDPI devices
     * @default `window.devicePixelRatio`
     */
    devicePixelRatio?: number;
    /**
     * Face searching algorithm to use
     * @default "GOOD"
     */
    faceSearchMode?: keyof typeof BanubaSDK.FaceSearchMode;
    /**
     * @hidden
     * @default "SYNCHRONOUS"
     */
    consistencyMode?: keyof typeof BanubaSDK.ConsistencyMode;
    /**
     * How to render processed frames
     * @default 0
     */
    cameraOrientation?: 0 | 90 | 180 | 270;
    /**
     * The maximum number of faces to be processed
     * @default 1
     */
    maxFaces?: 1 | 2 | 3 | 4;
    /**
     * A custom logger instance, pass `{}` to suppress all outputs
     * @default `window.console`
     * @example
     * ```ts
     * // suppressing `info` and `debug` messages, displaying only `error` and `warn` ones
     * Player.create({
     *   logger {
     *    error: console.error.bind(console),
     *    warn: console.warn.bind(console),
     *   },
     *   // ... other options
     * })
     * ```
     */
    logger?: Logger;
};
/** @category Core */
export declare type PlaybackOptions = {
    /**
     * Maximum render FPS
     * @default 30
     */
    fps?: number;
};
/** @category Core */
export declare type PlayerEventMap = {
    [Player.FRAME_RECEIVED_EVENT]: {
        averagedDuration: number;
        instantDuration: number;
    };
    [Player.FRAME_PROCESSED_EVENT]: {
        averagedDuration: number;
        instantDuration: number;
    };
    [Player.FRAME_RENDERED_EVENT]: {
        averagedDuration: number;
        instantDuration: number;
    };
    [Player.FRAME_DATA_EVENT]: BanubaSDK.FrameData;
    [Player.EFFECT_ACTIVATED_EVENT]: BanubaSDK.Effect;
};
/** @category Core */
export declare const defaultPlayerOptions: Required<PlayerOptions>;
/**
 * High level API over native SDK
 * @category Core
 */
export declare class Player
    extends EventTarget
    implements globalThis.EventTarget
{
    /**
     * Triggered when a frame is received from the specified {@link Input}
     * @event
     */
    static readonly FRAME_RECEIVED_EVENT = 'framereceived';
    /**
     * Triggered when a frame is processed by underlying neural networks
     * @event
     */
    static readonly FRAME_PROCESSED_EVENT = 'frameprocessed';
    /**
     * Triggered when a frame is rendered
     * @event */
    static readonly FRAME_RENDERED_EVENT = 'framerendered';
    /**
     * Triggered when a new {@link BanubaSDK.FrameData} is ready
     * @example
     * ```ts
     * player.addEventListener("framedata", (event) => {
     *   const frameData = event.detail
     *   const face = frameData
     *     .getFrxRecognitionResult()
     *     .getFaces()
     *     .get(0)
     *
     *   if (!face.hasFace()) return
     *
     *   const landmarks = face.getLandmarks()
     *
     *   for (let i = 0; i < landmarks.size(); ++i)
     *     console.log(landmarks.get(i))
     * })
     * ```
     * @event
     */
    static readonly FRAME_DATA_EVENT = 'framedata';
    /**
     * Triggered when an {@link Effect} is activated
     *
     * Note: By default the {@link Player} starts with an "empty" {@link Effect} applied
     * which does nothing but rendering
     *
     * @event
     */
    static readonly EFFECT_ACTIVATED_EVENT = 'effectactivated';
    private readonly _sdk;
    private readonly _preferences;
    private readonly _meta;
    private readonly _memory;
    private readonly _player;
    private readonly _effectManager;
    private _state;
    private _frames;
    get isPlaying(): boolean;
    /**
     * Creates {@link Player} instance
     * @returns {@link Player} instance
     */
    static create(options: SDKOptions & PlayerOptions): Promise<Player>;
    protected constructor(sdk: SDK, options?: PlayerOptions);
    /**
     * Uses the input as frames source
     * @example
     * ```ts
     * player.use(new Webcam())
     * ```
     */
    use(input: Input, options?: InputOptions): void;
    /**
     * Applies an effect to input
     * @example
     * ```ts
     * const octopus = new Effect("/path/to/Octopus.zip")
     *
     * player.applyEffect(octopus)
     * ```
     */
    applyEffect(effect: Effect): Promise<BanubaSDK.Effect>;
    /** Clears effect applied to input */
    clearEffect(): Promise<void>;
    /**
     * Evaluates JavaScript in context of applied effect.
     *
     * See {@link Effect.callJsMethod} for usage examples.
     *
     * @deprecated Use {@link Effect.evalJs} instead.
     */
    callJsMethod(methodName: string, methodJSONParams?: string): string;
    /** Sets effect volume from 0 to 1 */
    setVolume(level: number): void;
    private _setSurfaceSize;
    protected _pushFrame(
        { data, width, height, format }: ImageDataLike,
        parameters?: FeatureParameter[]
    ): void;
    protected _draw(): number;
    play({ fps }?: PlaybackOptions): Promise<void>;
    /** Stops input processing */
    pause(): Promise<void>;
    /**
     * Destroys the {@link Player} instance, clears all the resources used
     */
    destroy(): Promise<void>;
}
export interface Player {
    addEventListener<PlayerEvent extends keyof PlayerEventMap>(
        type: PlayerEvent,
        listener: (
            this: Player,
            evt: CustomEvent<PlayerEventMap[PlayerEvent]>
        ) => any,
        options?: boolean | AddEventListenerOptions
    ): void;
    addEventListener(
        type: string,
        listener: EventListenerOrEventListenerObject,
        options?: boolean | AddEventListenerOptions
    ): void;
    removeEventListener<PlayerEvent extends keyof PlayerEventMap>(
        type: PlayerEvent,
        listener: (
            this: Player,
            evt: CustomEvent<PlayerEventMap[PlayerEvent]>
        ) => any,
        options?: boolean | EventListenerOptions
    ): void;
    removeEventListener(
        type: string,
        listener: EventListenerOrEventListenerObject,
        options?: boolean | EventListenerOptions
    ): void;
    /** @internal */
    removeAllEventListeners(): void;
    /** @internal */
    dispatchEvent(event: Event): boolean;
}
export declare type FeatureParameter =
    | [x: number]
    | [x: number, y: number]
    | [x: number, y: number, z: number]
    | [x: number, y: number, z: number, w: number];
/** @category Core */
export declare class Effect {
    /** @internal */
    readonly name: string;
    private _player;
    private readonly _bundle;
    /**
     * Creates an effect from {@link Url}
     * @example
     * ```ts
     * const octopus = new Effect("/path/to/Octopus.zip")
     * ```
     */
    constructor(source: Url);
    /**
     * Creates an effect from {@link https://developer.mozilla.org/en-US/docs/Web/API/Request | Request}
     * @example
     * ```ts
     * const octopus = new Effect(new Request(
     *    "/path/to/Octopus.zip",
     *    { headers: { etag: "\"8b13dff520339ba88a610ceb58d4fa6b\"" } },
     * ))
     * ```
     */
    constructor(source: Request);
    /**
     * Creates an effect from {@link https://developer.mozilla.org/en-US/docs/Web/API/Blob | Blob}
     * @example
     * ```ts
     * const file = $("#file-upload").files[0] // File is subclass of Blob
     * const octopus = new Effect(file)
     * ```
     */
    constructor(source: Blob);
    /**
     * Creates an effect by preloading it from {@link Url}
     * @example
     * ```ts
     * const octopus = await Resource.preload("/path/to/Octopus.zip")
     * ```
     */
    static preload(source: Url): Promise<Effect>;
    /**
     * Creates an array of effects by preloading them from a list of {@link Url | Urls}
     * @example
     * ```ts
     * const [octopus, policeman] = await Effect.preload(["effects/Octopus.zip", "effects/Policeman.zip"])
     * ```
     */
    static preload(sources: Url[]): Promise<Effect[]>;
    /** Loads the effect data */
    protected _load(): Promise<void>;
    /** Loads the effect data, mounts it to the player's file system */
    protected _bind(player: Player): Promise<void>;
    /** Unmounts the effect data from the previously specified player's file system */
    protected _unbind(): void;
    /** Writes the file into the effect */
    /**
     * @example
     * ```ts
     * const makeup = new Effect("/path/to/Makeup.zip")
     * const filename = "nude_makeup.png"
     * const buffer = await fetch("/path/to/${filename}").then(r => r.arrayBuffer())
     *
     * // ...
     *
     * await makeup.writeFile(filename, buffer)
     * await makeup.evalJs(`Makeup.set("${filename}")`)
     * ```
     */
    writeFile(path: string, array: ArrayLike<number> | ArrayBufferLike): void;
    /**
     * @example
     * ```ts
     * const makeup = new Effect("/path/to/Makeup.zip")
     * const filename = "nude_makeup.png"
     * const file = $("#file-upload").files[0]
     *
     * // ...
     *
     * await makeup.writeFile(filename, file)
     * await makeup.evalJs(`Makeup.set("${filename}")`)
     * ```
     */
    writeFile(path: string, blob: Blob): Promise<void>;
    /**
     * Evaluates JavaScript method in context of the effect.
     *
     * The method won't evaluate if the effect is not applied to a player
     * @deprecated Use {@link Effect.evalJs} instead.
     *
     * @example
     * ```ts
     * const makeup = new Effect("/path/to/Makeup.zip")
     *
     * await player.applyEffect(makeup)
     *
     * // ...
     *
     * const electricBlueColor = "0.09 0.25 0.38"
     *
     * makeup.callJsMethod("Eyes.color", JSON.stringify(electricBlueColor))
     * ```
     */
    callJsMethod(
        methodName: string,
        methodJSONParams?: string
    ): string | undefined;
    /**
     * Evaluates JavaScript in context of the effect.
     *
     * The script won't evaluate if the effect is not applied to a player
     * @example
     * ```ts
     * const makeup = new Effect("/path/to/Makeup.zip")
     *
     * await player.applyEffect(makeup)
     *
     * // ...
     *
     * const electricBlueColor = "0.09 0.25 0.38"
     *
     * await makeup.evalJs(`Eyes.color("${electricBlueColor}")`)
     * ```
     */
    evalJs(code: string): Promise<string | undefined>;
}
/** @category Output */
export declare const Dom: {
    readonly render: (player: Player, container: HTMLElement | string) => void;
    readonly unmount: (container: HTMLElement | string) => void;
};
/**
 * Output photo settings
 * @category Output
 */
export declare type PhotoSettings = {
    /**
     * Output photo width
     * @default {@link Player}'s input frame width
     */
    width?: number;
    /**
     * Output photo height
     * @default {@link Player}'s input frame height
     */
    height?: number;
    /**
     * Output photo mime-type
     *
     * The mime-type support is platform specific,
     * e.g. "image/webp" is not supported on Safari 15.2.
     * See [toBlob](https://caniuse.com/?search=toBlob) and [toBlob type](https://caniuse.com/mdn-api_htmlcanvaselement_toblob_type_parameter_webp) for details.
     * @default "image/jpeg"
     */
    type?: 'image/png' | 'image/jpeg' | 'image/webp';
    /**
     * Output photo quality
     *
     * The quality support is platform specific,
     * e.g. Safari 15.2 does not support the setting.
     * See [toBlob](https://caniuse.com/?search=toBlob) and [toBlob quality](https://caniuse.com/mdn-api_htmlcanvaselement_toblob_quality_parameter) for mor details.
     * @default 0.92 for "image/jpeg"
     * @default 0.8 for "image/webp"
     */
    quality?: number;
};
/**
 * {@link Player} output to image
 * @category Output
 */
export declare class ImageCapture {
    private readonly _player;
    constructor(player: Player);
    /**
     * @param settings - Output photo settings
     * @returns Snapshot of the current {@link Player} state
     */
    takePhoto(settings?: PhotoSettings): Promise<Blob>;
}
declare const MediaStreamSSR: {
    new (): MediaStream;
    new (stream: MediaStream): MediaStream;
    new (tracks: MediaStreamTrack[]): MediaStream;
    prototype: MediaStream;
};
/**
 * {@link Player} output to {@link https://developer.mozilla.org/en-US/docs/Web/API/MediaStream/MediaStream | MediaStream}
 *
 * Commonly used for integration with third parties (e.g WebRTC video call SDK)
 *
 * ⚠️ The functionality might not be working on iOS Safari
 *
 * Track {@link https://bugs.webkit.org/show_bug.cgi?id=181663 | the corresponding issue on Webkit Bug Tracker} for a resolution status
 *
 * @category Output
 */
export declare class MediaStreamCapture extends MediaStreamSSR {
    private static readonly cache;
    constructor(player: Player);
    /**
     * @returns
     * Video {@link https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamTrack | MediaStreamTrack}
     * of given index from {@link https://developer.mozilla.org/en-US/docs/Web/API/MediaStream/getVideoTracks | MediaStream.getVideoTracks()} list
     */
    getVideoTrack(index?: number): MediaStreamTrack;
    /**
     * @returns
     * Audio {@link https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamTrack | MediaStreamTrack}
     * of given index from {@link https://developer.mozilla.org/en-US/docs/Web/API/MediaStream/getAudioTracks | MediaStream.getAudioTracks()} list
     */
    getAudioTrack(index?: number): MediaStreamTrack;
    /** Stops the capture */
    stop(): void;
}
declare const MediaRecorderSSR: {
    new (
        stream: MediaStream,
        options?: MediaRecorderOptions | undefined
    ): MediaRecorder;
    prototype: MediaRecorder;
    isTypeSupported(type: string): boolean;
};
export interface VideoRecorder extends MediaRecorder {
    /** Start video recording */
    start(): void;
    /** Pauses video recording */
    pause(): void;
    /** Resumes video recording after a pause */
    resume(): void;
}
/**
 * {@link Player} output to video
 *
 * ⚠️ The {@link VideoRecorder} works only on the {@link https://caniuse.com/?search=mediarecorder | platforms which supports MediaRecorder API}.
 *
 * @category Output
 */
export declare class VideoRecorder extends MediaRecorderSSR {
    constructor(player: Player, options: MediaRecorderOptions);
    /**
     * Stops video recording
     * @returns The recorder video
     */
    stop(): Promise<Blob>;
}
/** Current Banuba WebAR SDK version in use */
export declare const VERSION: string;

export {};
